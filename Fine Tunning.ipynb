{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96403e16-974c-4a7a-b8d3-6be4024818ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "train_features = pd.read_csv(\"train.csv\")\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "val_features = pd.read_csv(\"validation.csv\")\n",
    "val_labels = pd.read_csv(\"validation_labels.csv\")\n",
    "test_features = pd.read_csv('test.csv')\n",
    "test_labels = pd.read_csv('test_labels.csv')\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode categorical columns\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "categorical_cols = train_features.select_dtypes(include=['object']).columns\n",
    "train_features[categorical_cols] = encoder.fit_transform(train_features[categorical_cols])\n",
    "val_features[categorical_cols] = encoder.transform(val_features[categorical_cols])\n",
    "test_features[categorical_cols] = encoder.transform(test_features[categorical_cols])\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels.squeeze())\n",
    "val_labels = le.transform(val_labels.squeeze())\n",
    "test_labels = le.transform(test_labels.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f224f4c5-ca74-4fab-a9a4-05d6b7a20782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "Best training score: 0.7776876267748478\n",
      "Training classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      3622\n",
      "           1       0.78      0.69      0.73      1308\n",
      "\n",
      "    accuracy                           0.87      4930\n",
      "   macro avg       0.83      0.81      0.82      4930\n",
      "weighted avg       0.86      0.87      0.86      4930\n",
      "\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       776\n",
      "           1       0.49      0.47      0.48       280\n",
      "\n",
      "    accuracy                           0.73      1056\n",
      "   macro avg       0.65      0.64      0.65      1056\n",
      "weighted avg       0.72      0.73      0.73      1056\n",
      "\n",
      "Training confusion matrix:\n",
      "[[3363  259]\n",
      " [ 405  903]]\n",
      "Validation confusion matrix:\n",
      "[[637 139]\n",
      " [149 131]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Define StratifiedKFold for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define hyperparameters to try (including Gini and Entropy for criterion)\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Define a custom scorer using accuracy\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Define the GridSearchCV for Decision Tree\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "# Train the model using GridSearchCV\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# Display best model and scores\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best model:\", grid_search.best_params_)\n",
    "print(\"Best training score:\", grid_search.best_score_)\n",
    "\n",
    "# Predictions on the training and validation sets\n",
    "train_preds = best_model.predict(train_features)\n",
    "val_preds = best_model.predict(val_features)\n",
    "\n",
    "# Display classification reports\n",
    "print(\"Training classification report:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "\n",
    "print(\"Validation classification report:\")\n",
    "print(classification_report(val_labels, val_preds))\n",
    "\n",
    "# Confusion matrices\n",
    "print(\"Training confusion matrix:\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "print(\"Validation confusion matrix:\")\n",
    "print(confusion_matrix(val_labels, val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d522d58-3aeb-4276-91a6-3f8597cfebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM model: {'svc__C': 0.1, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
      "Best SVM training score: 0.7683569979716024\n",
      "SVM Training classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85      3622\n",
      "           1       0.58      0.76      0.66      1308\n",
      "\n",
      "    accuracy                           0.79      4930\n",
      "   macro avg       0.74      0.78      0.75      4930\n",
      "weighted avg       0.82      0.79      0.80      4930\n",
      "\n",
      "SVM Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       776\n",
      "           1       0.56      0.68      0.61       280\n",
      "\n",
      "    accuracy                           0.77      1056\n",
      "   macro avg       0.72      0.74      0.73      1056\n",
      "weighted avg       0.79      0.77      0.78      1056\n",
      "\n",
      "SVM Training confusion matrix:\n",
      "[[2904  718]\n",
      " [ 311  997]]\n",
      "SVM Validation confusion matrix:\n",
      "[[627 149]\n",
      " [ 91 189]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define a Pipeline for SVM with standardization\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardization\n",
    "    ('svc', SVC(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Define hyperparameters for the SVM\n",
    "param_grid_svm = {\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto', 0.1],\n",
    "    'svc__degree': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Define GridSearchCV for SVM\n",
    "grid_search_svm = GridSearchCV(pipeline, param_grid_svm, cv=cv, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "# Train the SVM model using GridSearchCV\n",
    "grid_search_svm.fit(train_features, train_labels)\n",
    "\n",
    "# Display best model and scores for SVM\n",
    "best_model_svm = grid_search_svm.best_estimator_\n",
    "print(\"Best SVM model:\", grid_search_svm.best_params_)\n",
    "print(\"Best SVM training score:\", grid_search_svm.best_score_)\n",
    "\n",
    "# Predictions on the training and validation sets for SVM\n",
    "train_preds_svm = best_model_svm.predict(train_features)\n",
    "val_preds_svm = best_model_svm.predict(val_features)\n",
    "\n",
    "# Display classification reports for SVM\n",
    "print(\"SVM Training classification report:\")\n",
    "print(classification_report(train_labels, train_preds_svm))\n",
    "\n",
    "print(\"SVM Validation classification report:\")\n",
    "print(classification_report(val_labels, val_preds_svm))\n",
    "\n",
    "# Confusion matrices for SVM\n",
    "print(\"SVM Training confusion matrix:\")\n",
    "print(confusion_matrix(train_labels, train_preds_svm))\n",
    "\n",
    "print(\"SVM Validation confusion matrix:\")\n",
    "print(confusion_matrix(val_labels, val_preds_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e92cc84-f295-43b1-90a2-1e92923a4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the best model (Decision Tree or SVM)\n",
    "with open('best_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "921438a5-3e82-4a2d-8f37-3150369058d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       776\n",
      "           1       0.53      0.44      0.48       281\n",
      "\n",
      "    accuracy                           0.75      1057\n",
      "   macro avg       0.67      0.65      0.66      1057\n",
      "weighted avg       0.74      0.75      0.74      1057\n",
      "\n",
      "Final Model Test confusion matrix:\n",
      "[[666 110]\n",
      " [156 125]]\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the pickle file\n",
    "with open('best_model.pkl', 'rb') as model_file:\n",
    "    final_model = pickle.load(model_file)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_preds = final_model.predict(test_features)\n",
    "\n",
    "# Display classification report and confusion matrix for the final model\n",
    "print(\"Final Model Test classification report:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "\n",
    "print(\"Final Model Test confusion matrix:\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05854ee2-0ea0-4a3d-a2f8-572c736e6590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab5fb9-34fd-41e8-8759-e79d3fff64bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
